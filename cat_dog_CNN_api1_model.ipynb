{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 훈련 데이터 복사하기\n",
    "train 폴더에서 cat, dog 폴더를 만들어 해당 사진을 이용시키고<br>\n",
    "훈련데이터와 검증데이터를 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_path = './dataset'\n",
    "copy_train_path = './datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(dogORcat_path, start_num, end_num, trainORval_path):\n",
    "    \n",
    "    image_paths = [os.path.join(original_dataset_path, 'train', dogORcat_path +'.'+str(i)+'.jpg')\n",
    "                  for i in range(start_num, end_num)]\n",
    "    \n",
    "    target_copy_paths = os.path.join(copy_train_path, trainORval_path, dogORcat_path)\n",
    "    \n",
    "    if not os.path.isdir(target_copy_paths):\n",
    "        os.makedirs(target_copy_paths)\n",
    "        \n",
    "    for image_path in image_paths:\n",
    "        shutil.copy(image_path, target_copy_paths)\n",
    "        \n",
    "    print('데이터 복사가 완료되었습니다.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 복사가 완료되었습니다.\n",
      "데이터 복사가 완료되었습니다.\n",
      "데이터 복사가 완료되었습니다.\n",
      "데이터 복사가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "copy_files('dog',0,10000,'train')\n",
    "copy_files('cat',0,10000,'train')\n",
    "copy_files('dog',10000,12500,'validation')\n",
    "copy_files('cat',10000,12500,'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 dog 개수 10000\n",
      "훈련데이터 cat 개수 10000\n",
      "검증데이터 dog 개수 2500\n",
      "검증데이터 cat 개수 2500\n"
     ]
    }
   ],
   "source": [
    "print('훈련데이터 dog 개수', len(os.listdir('./datasets/train/dog')))\n",
    "print('훈련데이터 cat 개수', len(os.listdir('./datasets/train/cat')))\n",
    "print('검증데이터 dog 개수', len(os.listdir('./datasets/validation/dog')))\n",
    "print('검증데이터 cat 개수', len(os.listdir('./datasets/validation/cat')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 함수 만들기\n",
    "## 콜백 함수를 만드는 이유\n",
    " - 모델 훈련시 통제를 할 수 있기 때문\n",
    " - 콜백 함수가 없으면 좋던 싫든 훈련이 끝날 때까지 아무것도 제어 할 수가 없다.\n",
    " - 콜백 함수는 베스트 가중치 선별 저장부터 모델 부적격시 자동 중단할 수 있다.\n",
    " - 다양한 기능이 있으니 관련 자료 찾아 보고 원하는 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './my_log'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "project_name = 'dog_cat_CNN_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file():\n",
    "    time = datetime.today()\n",
    "    yy = time.year\n",
    "    mon = time.month\n",
    "    dd = time.day\n",
    "    hh = time.hour\n",
    "    mm = time.minute\n",
    "    sec = time.second\n",
    "    time_name = str(yy) + str(mon) + str(hh) + str(mm) + str(sec) + 'my_' + project_name + '_model.h5'\n",
    "    file_name = os.path.join(save_dir, time_name)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [\n",
    "    \n",
    "#     keras.callbacks.TensorBoard(\n",
    "#     log_dir = save_dir, #텐션보드 그래프를 저장할 디렉토리를 지정\n",
    "#     write_graph = True, #graph 사용\n",
    "#     write_images = True #image 사용\n",
    "#     ),\n",
    "    \n",
    "    keras.callbacks.EarlyStopping(  # 학습중 평가시 모델 훈련 종료 시점을 지정\n",
    "    monitor = 'val_acc',            # 종료 시키기 위한 관찰 대상\n",
    "        patience = 10               # 모니터의 대상의 평가가 지정한 횟수 만큼 나아지지 않으면 훈련을 종료\n",
    "    ),                    #ex) monitor = 'val_acc', patience =5 이라면\n",
    "                            # 검증데이터 정확도가 5에포크만큼 나아지지 않으면 훈련을 종료합니다.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = save_file(),    # 모델 저장 위치\n",
    "    monitor = 'val_loss',      # 모델에 저장할 가중치, 주로 'val_loss' 사용\n",
    "    save_best_only = True      # 최상의 가중치만 기록여부\n",
    "    ),\n",
    "    \n",
    "#     keras.callbacks.ReduceLROnPlateau(\n",
    "#         monitor='val_acc',\n",
    "#         patience = 10,\n",
    "#         verbose = 1,\n",
    "#         factor =0.5,\n",
    "#         min_lr=0.00001)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras import layers, models, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "no_classes = 1\n",
    "epochs = 32\n",
    "image_height, image_width = 28,28     # 원래는 150,150\n",
    "input_shape = (image_height, image_width, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_api(input_shape):\n",
    "    \n",
    "    input_tensor = Input(input_shape, name = 'input')\n",
    "    \n",
    "    x = layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu')(input_tensor)\n",
    "    x = layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu')(x)\n",
    "    x = layers.Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(units = 1024, activation = 'relu')(x)\n",
    "    \n",
    "    output_tensor = layers.Dense(units = no_classes, activation = 'sigmoid', name = 'output')(x)\n",
    "    \n",
    "    model = models.Model([input_tensor], [output_tensor])\n",
    "    \n",
    "    model.compile(loss = losses.binary_crossentropy, optimizer = optimizers.RMSprop(lr = 0.0001), metrics = ['acc'])\n",
    "    \n",
    "    return model\n",
    "                                                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 102,855,745\n",
      "Trainable params: 102,855,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_api(input_shape).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(copy_train_path, 'train'),\n",
    "    target_size = (image_height, image_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(copy_train_path, 'validation'),\n",
    "    target_size = (image_height, image_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= 'binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 102,855,745\n",
      "Trainable params: 102,855,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newType_model = cnn_api(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newType_model = cnn_api(input_shape)\n",
    "newType_model\n",
    "hist = newType_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 20000//batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 5000//batch_size,\n",
    "    callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "epochs = range(1,len(train_acc)+1)\n",
    "\n",
    "plt.plot(epochs, train_acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Val acc')\n",
    "plt.title('Training and Val loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label= 'Val loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐셔보드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. 과대 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
